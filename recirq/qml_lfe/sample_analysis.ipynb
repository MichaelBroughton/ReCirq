{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbdd6c60",
   "metadata": {
    "id": "35a4782cd01c"
   },
   "source": [
    "# Learning states with conventional experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38297cf2",
   "metadata": {
    "id": "2eb02bf1e842"
   },
   "source": [
    "Using randomized Pauli measurement from https://www.nature.com/articles/s41567-020-0932-7 to predict which of the two Pauli observables have a higher magnitude of expectation value.\n",
    "The number of experiments need to scale exponentially with the system size $n$ to make accurate prediction.\n",
    "\n",
    "We perform measurement error mitigation as described in the manuscript (Appendix A.2.d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9c8af31",
   "metadata": {
    "id": "b68ecbbc6515"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.465\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import moment\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier\n",
    "from os import listdir\n",
    "import random\n",
    "from os.path import isfile, join\n",
    "\n",
    "idx_to_pauli = [\"Z\", \"X\", \"Y\"]\n",
    "\n",
    "# Measurement-error-mitigated expectation value prediction\n",
    "def predict_exp(data, list_P, calib_2x2, inverse_cnt=20):\n",
    "    ttl_sum, ttl_cnt = 0, 0\n",
    "\n",
    "    for rep in range(inverse_cnt):\n",
    "        for _, a in enumerate(data):\n",
    "            val = 1\n",
    "            \n",
    "            for i, pauli in enumerate(list_P):\n",
    "                if pauli == \"I\": continue\n",
    "\n",
    "                p1, q1 = calib_2x2[2*i][0, 0], calib_2x2[2*i][1, 1]\n",
    "                \n",
    "                val *= 1 / (p1 + q1 - 1)\n",
    "                \n",
    "                a[i] = int(a[i])\n",
    "                b1 = int(a[i] // 2)\n",
    "                s1 = int(a[i] % 2)\n",
    "\n",
    "                if s1 == 0:\n",
    "                    if random.choices([0, 1], weights = [q1, 1-q1], k=1)[0] == 1:\n",
    "                        s1 = 1 - s1\n",
    "                        val *= -1\n",
    "                else:\n",
    "                    if random.choices([0, 1], weights = [p1, 1-p1], k=1)[0] == 1:\n",
    "                        s1 = 1 - s1\n",
    "                        val *= -1\n",
    "\n",
    "                if idx_to_pauli[b1] == pauli:\n",
    "                    val *= (1 if s1 == 0 else -1)\n",
    "                else:\n",
    "                    val = 0\n",
    "            \n",
    "            if val != 0:\n",
    "                ttl_sum += val\n",
    "                ttl_cnt += 1\n",
    "    return (ttl_sum / ttl_cnt if ttl_cnt > 0 else None)\n",
    "\n",
    "mypath = \"data/\"\n",
    "\n",
    "n = 8\n",
    "number_of_experiment = 500\n",
    "correct_cnt, total_cnt = 0, 0\n",
    "\n",
    "# Noiseless simulation (measurement error = 0)\n",
    "calib_2x2 = []\n",
    "for i in range(2*n):\n",
    "    conf_mtx = np.zeros((2, 2))\n",
    "    conf_mtx[0][0] = 1\n",
    "    conf_mtx[0][1] = 0\n",
    "    conf_mtx[1][0] = 0\n",
    "    conf_mtx[1][1] = 1\n",
    "    calib_2x2.append(conf_mtx)\n",
    "\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "for file in onlyfiles * 5:\n",
    "    splt = file.split(\"-\")\n",
    "\n",
    "    if splt[0] != \"C\": continue\n",
    "    if int(splt[2]) != n: continue\n",
    "    if len(splt) != 5: continue\n",
    "\n",
    "    pauli = splt[-1][:-4]\n",
    "\n",
    "    binaryout = np.load(join(mypath, file))\n",
    "    basisout = np.load(join(mypath, \"-\".join(splt[:-1]) + \"-\" + splt[-1][:-4] + \"-basis.npy\"))\n",
    "    fulldata = basisout*2 + binaryout\n",
    "\n",
    "    data = np.random.permutation(fulldata)[:number_of_experiment]\n",
    "\n",
    "    rand_P = [random.choice([\"I\", \"X\", \"Y\", \"Z\"]) for i in range(n)]\n",
    "    while min([x == y for (x, y) in zip(pauli, rand_P)]) == 1 or sum([p == \"I\" for p in rand_P]) == (n):\n",
    "        rand_P = [random.choice([\"I\", \"X\", \"Y\", \"Z\"]) for i in range(n)]\n",
    "\n",
    "    pred1 = predict_exp(data, pauli, calib_2x2)\n",
    "    pred2 = predict_exp(data, rand_P, calib_2x2)\n",
    "    \n",
    "    if pred1 is None or pred2 is None:\n",
    "        correct_cnt += 0.5\n",
    "    elif abs(pred1) > abs(pred2):\n",
    "        correct_cnt += 1\n",
    "    total_cnt += 1\n",
    "\n",
    "print(\"ACC:\", correct_cnt / total_cnt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0295ddca",
   "metadata": {
    "id": "a1776a208967"
   },
   "source": [
    "# Learning states with quantum-enhanced experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbf3b6f",
   "metadata": {
    "id": "e6cef1fa4c89"
   },
   "source": [
    "We begin by presenting the supervised neural network model described in the manuscript (See Appendix A.2.d).\n",
    "\n",
    "We train a supervised neural network model using noiseless simulation data from small system sizes. Then we use the trained neural network model on the noisy experimental data obtained from performing quantum-enhanced experiments. The neural network model has three layers. Each of the outer layers runs the preceding inner layer multiple times. In the following, we describe each layer of the neural network model.\n",
    "\n",
    "We begin with the inner layer, which is given by the following code block.\n",
    "Only the inner layer contains trainable parameters. The intermediate layer and the outer layer are both fixed operations based on outputs from the inner layer, which will go through back-propagation but will not be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5842223e",
   "metadata": {
    "id": "a7df3f4c516f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.encoder = nn.Embedding(16, 30)\n",
    "        self.rnn = nn.GRU(30, 30, 1)\n",
    "        self.decoder = nn.Linear(30, 2)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        batch_size = input.size(0)\n",
    "        encoded = self.encoder(input)\n",
    "        output, hidden = self.rnn(encoded.view(1, batch_size, -1), hidden)\n",
    "        output = self.decoder(output.view(batch_size, -1)).view(batch_size, -1)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return Variable(torch.zeros(1, batch_size, 30))\n",
    "\n",
    "decoder = CharRNN()\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e807619",
   "metadata": {
    "id": "7ddd84812965"
   },
   "source": [
    "Next, we discuss the training process in the neural network model.\n",
    "We use noiseless simulation data (for small system sizes $n < 8$) to train the recurrent neural network.\n",
    "During training, we pick a state $\\rho = 2^{-n}\\left(I+ \\alpha P\\right)$ where $\\alpha \\in \\{-0.95, 0.95\\}$ and $P$ is an $n$-qubit Pauli operator, and pick an $n$-qubit Pauli operator $Q$ that is equal to $P$ with probability $1/2$ and is not equal to $P$ with probability $1/2$.\n",
    "We encode the training data into two Pytorch Variable LongTensors, `inp` and `target`.\n",
    "The encoding is defined by the following.\n",
    "\n",
    "1. The Pytorch Variable LongTensor `inp` is a tensor of size $b \\times n$, where $b$ is the number of quantum-enhanced experiments we performed, $n$ is the number of qubits, and each entry of `inp` is an integer from $0$ to $15$.\n",
    "    The $(t, i)$-th entry of `inp` encodes the component of $Q$ on qubit $i$ (a choice of $4$ for $I, X, Y, Z$) and the Bell measurement outcome on qubit $i$ from the $t$-th quantum-enhanced experiment (also a choice of $4$).\n",
    "    Each entry takes a total of $16$ possible values.\n",
    "    \n",
    "    \n",
    "2. The Pytorch Variable LongTensor `target` is a tensor of size $1$. The entry in `target` is equal to $1$ if $P = Q$, and is equal to $0$ if $P \\neq Q$.\n",
    "\n",
    "Given `inp` of size $b \\times n$ and `target` of size $1$, we train the neural network model using the code block below.\n",
    "We are using the cross entropy loss, `criterion = nn.CrossEntropyLoss()` from the previous code block, and employ the Adam optimizer, which is a gradient-based optimization algorithm that adaptively estimates lower-order moments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "951961d6",
   "metadata": {
    "id": "1e841550132f"
   },
   "outputs": [],
   "source": [
    "def train(inp, target, b, n):\n",
    "    decoder.train()\n",
    "    \n",
    "    hidden = decoder.init_hidden(b)\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "    for c in range(n):\n",
    "        output, hidden = decoder(inp[:,c], hidden)\n",
    "        if c == n-1:\n",
    "            loss += criterion(torch.mean(output.view(b, -1), dim=0, keepdim=True),\\\n",
    "                              target[:])\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data.item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb87a84e",
   "metadata": {
    "id": "f2309acd349e"
   },
   "source": [
    "Also, we are simultaneously running the $b$ repetitions of the inner layer for each outcome from a single quantum-enhanced experiment in the line `output, hidden = decoder(inp[:,c], hidden)` to leverage parallel computing.\n",
    "Then, we average over the $b$ repetitions of the inner layer through `torch.mean(output.view(b, -1), dim=0, keepdim=True)`.\n",
    "Also, note that `torch.mean(output.view(b, -1), dim=0, keepdim=True)` is a two-dimensional real vector, denoted as $v = (v_0, v_1)$.\n",
    "When `target` is $a \\in \\{0, 1\\}$, the loss function is given by\n",
    "\\begin{equation}\n",
    "    -\\log\\left( \\frac{\\mathrm{e}^{v_a}}{\\mathrm{e}^{v_0} + \\mathrm{e}^{v_1}} \\right).\n",
    "\\end{equation}\n",
    "The two real values $v_0$, $v_1$ are combined to produce a probability distribution\n",
    "\\begin{equation} \\label{eq:prob-NN}\n",
    "    \\frac{\\mathrm{e}^{v_0}}{\\mathrm{e}^{v_0} + \\mathrm{e}^{v_1}} = 1 - \\frac{1}{\\mathrm{e}^{v_0 - v_1} + 1}, \\quad \\frac{\\mathrm{e}^{v_1}}{\\mathrm{e}^{v_0} + \\mathrm{e}^{v_1}} = \\frac{1}{\\mathrm{e}^{v_0 - v_1} + 1},\n",
    "\\end{equation}\n",
    "indicating which of $a=0$ and $a=1$ is more likely.\n",
    "If $v_0 - v_1$ is large, then $a=0$ corresponding to $P \\neq Q$ is more likely. On the other hand, if $v_0 - v_1$ is small, then $a=1$ corresponding to $P = Q$ is more likely.\n",
    "The two lines `loss.backward()` and `decoder_optimizer.step()` computes the gradient through back-propagation and update the model using the rule given in Adam optimizer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b19ce33",
   "metadata": {
    "id": "08f9b224894c"
   },
   "source": [
    "Finally, we discuss the prediction process in the neural network model.\n",
    "Due to the significant amount of measurement errors, we employ a form of measurement error mitigation.\n",
    "We first characterize the measurement errors for every qubit assuming the zero state preparations and $X$-gates are perfect.\n",
    "For each qubit $i$, we obtain a $2\\times 2$ matrix specifying the probability to measure $0$ or $1$ if the qubit is in $\\lvert 0 \\rangle\\!\\langle 0\\rvert$ or $\\lvert 1 \\rangle\\!\\langle 1\\rvert$.\n",
    "We store that as a list of $2 \\times 2$ NumPy array called `calib_2x2`.\n",
    "We then expand the data, referred to as `data` in the Python code, obtained from the quantum-enhanced experiments, which is a two-dimensional NumPy array of size $b \\times (2n)$.\n",
    "Basically, we expand each measurement to $20$ measurements with a real-valued coefficient associated to each of the expanded measurements.\n",
    "Therefore, `data_expanded` is a two-dimensional array of size $(20 b) \\times (2n)$ and `coefficients` is a one-dimensional array of size $20 b$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6274defc",
   "metadata": {
    "id": "5ceb790c8f0c"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def noise_inversion(data, calib_2x2, inverse_cnt=20):\n",
    "    data_expanded, coefficients = [], []\n",
    "    for t in range(len(data)):\n",
    "        for r in range(inverse_cnt):\n",
    "            val = 1.0\n",
    "            single_data = []\n",
    "            \n",
    "            for i in range(len(data[t])):\n",
    "                s1 = data[t][i]\n",
    "                p = calib_2x2[i][1, 1] if s1 == 0 else calib_2x2[i][0, 0]\n",
    "                if random.choices([0, 1], weights = [p, 1-p], k=1)[0] == 1:\n",
    "                    s1 = 1 - s1\n",
    "                    val *= -1\n",
    "                single_data.append(s1)\n",
    "\n",
    "            data_expanded.append(single_data)\n",
    "            coefficients.append(val)\n",
    "    return data_expanded, coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5226ed62",
   "metadata": {
    "id": "661688ac3901"
   },
   "source": [
    "After obtaining `data_expanded`, we construct two Pytorch Variable LongTensor `inp1` and `inp2`.\n",
    "Both are tensors of size $(20 b) \\times n$, where $b$ is the number of quantum-enhanced experiments we performed, $n$ is the number of qubits, and each entry of `inp1` and `inp2` is an integer from $0$ to $15$ similar to the training process.\n",
    "Then the neural network make a prediction using the following code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc4cdba6",
   "metadata": {
    "id": "da7f46e53682"
   },
   "outputs": [],
   "source": [
    "def predict_one(inp, coefficients, n):\n",
    "    decoder.eval()\n",
    "\n",
    "    hidden = decoder.init_hidden(len(inp))\n",
    "    decoder.zero_grad()\n",
    "    for c in range(n):\n",
    "        output, hidden = decoder(inp[:,c], hidden)\n",
    "        if c == n-1:\n",
    "            pred = torch.matmul(coefficients, output.view(len(inp), -1)).view(2).detach().numpy()\n",
    "    return pred\n",
    "\n",
    "def predict(inp1, coef1, inp2, coef2, n):\n",
    "    pred1 = predict_one(inp1, coef1, n)\n",
    "    pred2 = predict_one(inp2, coef2, n)\n",
    "\n",
    "    return 1 if (pred1[0] - pred1[1]) < (pred2[0] - pred2[1]) else 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6648e5",
   "metadata": {
    "id": "9ebcc3c70099"
   },
   "source": [
    "We consider `pred1[0] - pred1[1]` based on the discussion above.\n",
    "If `pred1[0] - pred1[1]` is small, then it is more likely that $P = Q_1$.\n",
    "If `pred1[0] - pred1[1]` is small, then it is more likely that $P = Q_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4cf3be",
   "metadata": {
    "id": "3c9ce2bd7530"
   },
   "source": [
    "We now present the complete code for training the neural network and making predictions on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cebeda72",
   "metadata": {
    "id": "856a69fb100e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                          | 1/3000 [00:00<05:08,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10000 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▎                                      | 101/3000 [00:07<04:04, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.7010987719893456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▋                                     | 201/3000 [00:17<03:26, 13.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.7056578263640404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▏                                  | 252/3000 [01:11<4:30:58,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████                                    | 302/3000 [01:15<03:25, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.6880712875723839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▎                                  | 402/3000 [01:22<03:25, 12.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.6891044595837593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▋                                 | 498/3000 [01:30<03:23, 12.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.6756314340233803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▎                               | 502/3000 [02:16<3:22:40,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████                                | 602/3000 [02:24<02:59, 13.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.6718862247467041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████▎                              | 702/3000 [02:32<03:02, 12.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.634903935790062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████▌                            | 752/3000 [03:23<3:07:46,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 0.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████▋                             | 802/3000 [03:27<02:48, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.6466570368409157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████                            | 902/3000 [03:35<02:51, 12.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.5890597422420979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████▎                          | 998/3000 [03:42<02:26, 13.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.5411157709360123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████▎                        | 1001/3000 [04:30<3:17:40,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████▎                        | 1100/3000 [04:39<02:48, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.4691870480775833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████▌                       | 1201/3000 [04:48<02:38, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.3367442492954433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████▍                     | 1251/3000 [05:46<3:41:02,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████▉                      | 1300/3000 [05:51<02:59,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.247039335956797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████████▏                    | 1400/3000 [06:02<02:29, 10.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.13162528837798163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████▍                   | 1498/3000 [06:11<02:17, 10.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.10982349822064862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████▌                  | 1502/3000 [06:58<2:03:20,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|████████████████████▊                  | 1602/3000 [07:06<01:47, 13.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.12103115448204335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████▏                | 1702/3000 [07:15<01:59, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.09271536265936448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████████████████████▌               | 1751/3000 [08:06<2:01:00,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████▍               | 1801/3000 [08:10<01:32, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.05863530368718784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|████████████████████████▋              | 1902/3000 [08:19<01:53,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.07748784126131796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████▉             | 1999/3000 [08:29<01:58,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.05077959488233318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████▋            | 2001/3000 [09:26<2:54:39, 10.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████▎           | 2101/3000 [09:38<01:40,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.06307093953641014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████▌          | 2201/3000 [09:52<01:42,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.07622316960681928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████▊         | 2251/3000 [10:57<1:38:08,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|█████████████████████████████▉         | 2301/3000 [11:02<01:23,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.037912848099367694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████▏       | 2401/3000 [11:14<01:10,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.03832163298844535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████▍      | 2499/3000 [11:30<01:29,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.02484862251330469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████▊      | 2501/3000 [12:30<1:43:46, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████▊     | 2601/3000 [12:40<00:45,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.04351241139576814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████    | 2700/3000 [12:51<00:28, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.03283559548246558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████▊   | 2751/3000 [13:49<31:55,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████████████▍  | 2802/3000 [13:55<00:21,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.027417695932817877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████████████████████████████████▋ | 2900/3000 [14:05<00:08, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.018936340993477643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████▉| 2999/3000 [14:18<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 0.02224759492623889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3000/3000 [15:09<00:00,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import cirq\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import random\n",
    "from os.path import isfile, join\n",
    "from cirq import Simulator\n",
    "simulator = Simulator()\n",
    "\n",
    "all_paulis = dict([(\"I\",0), (\"X\",1), (\"Y\",2), (\"Z\",3)])\n",
    "\n",
    "def entire_process_predict_Pauli_observable(qubits, hidden_P, num_rep):\n",
    "    n = len(qubits) // 2\n",
    "    output = []\n",
    "    \n",
    "    sign_p = -1 if np.random.random() < 0.5 else 1\n",
    "    for _ in range(num_rep):\n",
    "        circuit = cirq.Circuit()\n",
    "\n",
    "        last_i = 0\n",
    "        for i, pauli in enumerate(hidden_P):\n",
    "            if pauli != \"I\":\n",
    "                last_i = i\n",
    "            \n",
    "        for twocopy in [0, 1]:\n",
    "            parity = sign_p\n",
    "            for i, pauli in enumerate(hidden_P):\n",
    "                if pauli != \"I\":\n",
    "                    if last_i == i:\n",
    "                        if parity == -1:\n",
    "                            circuit += cirq.X(qubits[2*i+twocopy])\n",
    "                    elif random.choice([0, 1]) == 1:\n",
    "                        parity *= -1\n",
    "                        circuit += cirq.X(qubits[2*i+twocopy])\n",
    "                else:\n",
    "                    if random.choice([0, 1]) == 1:\n",
    "                        circuit += cirq.X(qubits[2*i+twocopy])\n",
    "\n",
    "                if pauli == \"X\":\n",
    "                    circuit += cirq.H(qubits[2*i+twocopy])\n",
    "                if pauli == \"Y\":\n",
    "                    circuit += cirq.H(qubits[2*i+twocopy])\n",
    "                    circuit += cirq.S(qubits[2*i+twocopy])\n",
    "\n",
    "        for i, pauli in enumerate(hidden_P):\n",
    "            circuit += cirq.CNOT(qubits[2*i], qubits[2*i+1])\n",
    "            circuit += cirq.H(qubits[2*i])\n",
    "\n",
    "        for i, qubit in enumerate(qubits):\n",
    "            circuit += cirq.measure(qubit, key='q{}'.format(i))\n",
    "\n",
    "        samples = simulator.run(circuit, repetitions=1)\n",
    "\n",
    "        raw_samples = np.zeros(len(qubits), dtype=int)\n",
    "        for i in range(len(qubits)):\n",
    "            raw_samples[i] = samples.data['q{}'.format(i)]\n",
    "\n",
    "        output.append(raw_samples)\n",
    "\n",
    "    return output\n",
    "\n",
    "def sample_one(b_experi, n_qubits):\n",
    "    qubits = cirq.GridQubit.rect(n_qubits, 2)\n",
    "\n",
    "    true_p = [random.choice([\"I\", \"X\", \"Y\", \"Z\"]) for i in range(n_qubits)]\n",
    "    while sum([p == \"I\" for p in true_p]) == n_qubits:\n",
    "        true_p = [random.choice([\"I\", \"X\", \"Y\", \"Z\"]) for i in range(n_qubits)]\n",
    "    data = entire_process_predict_Pauli_observable(qubits, true_p, b_experi)\n",
    "\n",
    "    true_or_fake = random.choice([0, 1])\n",
    "\n",
    "    rand_P = [random.choice([\"I\", \"X\", \"Y\", \"Z\"]) for i in range(n_qubits)]\n",
    "    while min([x == y for (x, y) in zip(true_p, rand_P)]) == 1 or sum([p == \"I\" for p in rand_P]) == n_qubits:\n",
    "        rand_P = [random.choice([\"I\", \"X\", \"Y\", \"Z\"]) for i in range(n_qubits)]\n",
    "    \n",
    "    fake_p = true_p if true_or_fake == 1 else rand_P\n",
    "    \n",
    "    input_X = np.zeros((len(data), n_qubits))\n",
    "    for i in range(len(data)):\n",
    "        for j in range(0, len(data[i]), 2):\n",
    "            input_X[i][j//2] = data[i][j]*2 + data[i][j+1]\n",
    "            input_X[i][j//2] += all_paulis[fake_p[j//2]] * 4\n",
    "\n",
    "    return input_X, true_or_fake\n",
    "\n",
    "def random_training_set(b_experi, n_qubits):\n",
    "    input_X, true_or_fake = sample_one(b_experi, n_qubits)\n",
    "\n",
    "    inp = torch.LongTensor(input_X)\n",
    "    target = torch.LongTensor(1)\n",
    "    target[0] = true_or_fake\n",
    "\n",
    "    inp = Variable(inp)\n",
    "    target = Variable(target)\n",
    "    return inp, target\n",
    "\n",
    "def construct_from_exp(data, chosen_pauli, calib_2x2, n_qubits):\n",
    "    data, coef = noise_inversion(data, calib_2x2, inverse_cnt=20)\n",
    "\n",
    "    input_X = np.zeros((len(data), n_qubits))\n",
    "    for i in range(len(data)):\n",
    "        for j in range(0, len(data[i]), 2):\n",
    "            input_X[i][j//2] = data[i][j]*2 + data[i][j+1]\n",
    "            input_X[i][j//2] += all_paulis[chosen_pauli[j//2]] * 4\n",
    "    inp = torch.LongTensor(input_X)\n",
    "    inp = Variable(inp)\n",
    "\n",
    "    coe_sign = torch.FloatTensor(coef) / len(coef)\n",
    "    \n",
    "    return inp, coe_sign\n",
    "\n",
    "def get_accuracy(n):\n",
    "    mypath = \"data/\"\n",
    "    correct_cnt, total_cnt = 0, 0\n",
    "    \n",
    "    # Noiseless simulation (measurement error = 0)\n",
    "    calib_2x2 = []\n",
    "    for i in range(2*n):\n",
    "        conf_mtx = np.zeros((2, 2))\n",
    "        conf_mtx[0][0] = 1\n",
    "        conf_mtx[0][1] = 0\n",
    "        conf_mtx[1][0] = 0\n",
    "        conf_mtx[1][1] = 1\n",
    "        calib_2x2.append(conf_mtx)\n",
    "\n",
    "    onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "    for file in onlyfiles * 2:\n",
    "        splt = file.split(\"-\")\n",
    "        \n",
    "        if splt[0] != \"Q\": continue\n",
    "        if int(splt[2]) != n: continue\n",
    "        \n",
    "        true_P = splt[-1][:-4]\n",
    "        data = np.random.permutation(np.load(join(mypath, file)))\n",
    "\n",
    "        rand_P = [random.choice([\"I\", \"X\", \"Y\", \"Z\"]) for i in range(n)]\n",
    "        while min([x == y for (x, y) in zip(true_P, rand_P)]) == 1 or sum([p == \"I\" for p in rand_P]) == n:\n",
    "            rand_P = [random.choice([\"I\", \"X\", \"Y\", \"Z\"]) for i in range(n)]\n",
    "\n",
    "        pred = predict(*construct_from_exp(data, true_P, calib_2x2, n),\n",
    "                       *construct_from_exp(data, rand_P, calib_2x2, n), n)\n",
    "\n",
    "        if pred == 1:\n",
    "            correct_cnt += 1\n",
    "        total_cnt += 1\n",
    "\n",
    "    return correct_cnt / total_cnt\n",
    "\n",
    "print(\"Training for %d examples...\" % 10000)\n",
    "\n",
    "store_all_loss = []\n",
    "store_all_acc = []\n",
    "for epoch in tqdm(range(1, 3000 + 1), position=0, leave=True):\n",
    "    n_qubits = random.choice(range(2, min(8, 4 + (epoch // 1000))))\n",
    "    loss = train(*random_training_set(15, n_qubits), 15, n_qubits)\n",
    "    store_all_loss.append(loss)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"LOSS\", np.mean(store_all_loss[-100:]))\n",
    "    if epoch % 250 == 0:\n",
    "        n = 8 # predict on data for system size n = 8\n",
    "        store_all_acc.append(get_accuracy(n))\n",
    "        print(\"ACC\", store_all_acc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99a23cb",
   "metadata": {
    "id": "24519510bfeb"
   },
   "source": [
    "# Learning dynamics with conventional experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4788589f",
   "metadata": {
    "id": "cd2a069faabd"
   },
   "source": [
    "Using kernel principal component analysis to analyze data from conventional experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73b49942",
   "metadata": {
    "id": "0d64242102a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fcc5c1ecf70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMIAAADcCAYAAAAiPX7aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAe7UlEQVR4nO3de3BU9f3/8ec5e/aSzeYCSUgMQcFisJJAohFQzFiw3tBxWqtFhKp1UNCCdkQHqqK1zrfVqhXFDmqllKJodWrr1NsI/NSxWG8gqCgidwIJm+vmtvfz/v2xZMkm4R4l4Psx45Bzzud8zmc/e167n3P2nKMhIoJS33Pm0W6AUn2BBkEpNAhKARoEpQANglIAWL1dYSgU4osvviAvLw+Hw9Hb1SvVTTwep7a2lpKSEjwez2HV0etB+OKLL5g8eXJvV6vUAT333HNUVFQc1rq9HoS8vDwg0aiCgoLerl6pbmpqapg8eXJy3zscvR6EjuFQQUEBRUVFvV29Uvt0JENxPVhWCg2CUoAGQSlAg6AUoEFQCtAgKAVoEJQCNAhKARoEpQANglKABkEpQIOgFKBBUArQICgFaBCUAjQISgEaBKUADYJSgAZBKUCDoBSgQVAK0CAoBWgQlAI0CEoBGgSlAA2CUoAGQSlAg6AUoEFQCtAgKAVoEJQCNAhKARoEpQANglKABkEpQIOgFKBBUArQICgFaBCUAjQISgEaBKUADYJSgAZBKUCDoBSgQVAK0CAoBWgQlAI0CEoBGgSlAA2CUoAGQSlAg6AUoEFQCtAgKAVoEJQCNAhKARoEpQANglKABkEpQIOgFKBBUArQICgFaBCUAjQISgEaBKUADYJSgAZBKUCDoBSgQVAK0CAcF0QEse1u86pqbYJh6VY+GBZsO7GOSPfl30fW0W5AXyehMJgGhsuV2OECAWJtISyvGyMrC8Ps/lkiIhiGse86RQi0QbbP6DZ/f+t1qycSIVa1E7uhEUQwfek4Ck/AyMxke63Q3AbNQWFIPqS5E/W2hYTt3zTiC1ST5wpiOEwc/frhKBqI4XId9LaPNxqEfYjXNxDftSsRBMBwWkg4Qm0zhKOQ6wnjdhlYJSVY2VnJ9eoCQltIOHEAKTu1iCBNTcRb26hpNmly9qc9x01hjpFcvs0veN3gcYHTsXfn7YlEo0S/Wo9Eosl5dmsb9oaN7M4eQrOVnXgdcdiyOxEGW2DHhnqcO7YQBupckJtlE69vwG5txXnaDzGs7+cu8f181QcQb2ggtnlLclpEiG3aTGMgjt/OIiOwi7Z4K7YLrM/W4RpVgev0MupbDKobEkON7f5EGCJR2LU7TEHDRsxwiOpGwd8IPu8umopOBPI4oT9s8wstzVEa6hqwY3F8OT5O+kHWPsMQ99emhGBPQ6lrEUKBnfCD7L1l47B+hw0i+Gp2JeeHIong5mYB4Qh2bS2OE07orW48pmgQehDfVZ0yLe3tNDZFaW6O0i+wDtthETYMEEgjCl98SUtrjOqTKpLrNLfDxl02sTiYm7eyOxzEtoW6AAjQ1Cr4tm2jweuluiGNtJY6zKodxNptBIjWGez0p1N45il4053d2mgHAqkz9oQgGAKTEEYkjLjcAISjQm1AsCIh0kJhLMfe1TqHwW5q1iCoBIlGkWAoZV5tbZiWNsEVbMERDWE7fNgihKMGsbjgdESJbKrCyDsV8foAiIUibK418RChsK2ZujZoaRfSXBAXg1BEEgeyG/3EsnLIqd5GrD2EK9yKZceJW05CsQg712ylqGJoyjeD2DYSDCLhMIY7sbPvqhcC7YLPs2eotadsRwhEEkOj5nbISgdHp0ObjjDkZXx7/drXaRC66nLwW91gU99m4QGsSBDYu0PG4kIoAlHDJN2KYjU3YMeiGDW7CDaFyBaIGw787RFCJD7VW8MAggFEYtBWHyEtVEebvwlPayMxAxx7jhEINhOJxdhSMIghRW7S3Abx6hri1TXYDQ3Y9Y3gdBLO7E84lkYkatCK4Ej34m93kWsl2tdxYiju8mCle3CYqUFnT1va3VnsrLY5aYCBw9H9QN6uq8Oub0BiMUyfDzN/AGZaWq91/dGkQehEwmHi/lrs5makPUiz4cXf6kXcXsR0YBsODEeiy2wbYnGIiUHQcGMHwdnWjlVXS6Cdvaclw0EctdU43T5c8RB2LE7cchNJyyRuemjFQ8zfRHagkbiRyGEoLKQ7ojiJY1dX0R4YwRani5NMP1b1TgDMzCzsljbC7RFaG3bjzCskw+uiodWg1leIKyrUBgzyskDEoCUoOBzgHlwEOzbtTQeJbWbneqk2comH9h5cd4RBRIht3Izd1JRYIRIhunMXfLUe65RTsIachOHoNN46BmkQ9rBbW4lt+AaJ25hpHmKNjVhtbfQ30mlw5RLMyseIRvC0NGDbiSBgGkRcWYmzQ2leWhqCYAumbWNFggjQbnvIjbfha22m1eHDFMETaia7qYp2ZwYtOR48wQBxGywHmHactFAAQ+KYFngsA+fWz4n7yqGlZm+DTZNITgGBSADTbMUMthIZcDKBzAG0xtNxBQVfGskw2Da0haFWMsgbXIxV78dsb8G0HGQX9afGmU98z89KwXBqGOzGpmQI7KYAdn19shmRtZ8hrS1Yxadger3f3RvWyzQIe8S2bkPie36UcrqwBg4kvbkZGtqJeg12e39A7cmnk7tuJWm1VdiGg7jlwmXE8UorzaYP3+4t2LZgio2xZ4Tli0URwyYuYCJ4QgEcdhTBQAwDZyyEN9SEMx7CNt14QgFM4ok2xcGZ7sKSGP39X1PXZpObZWI5DNrDQkObiWT0I57Rj5DhZmfGEAAy4tDSbtC6Jwz+JhiQbWCY0BoUaj1ecoqG4HAYFGRDTSPEU3+PSwmD3dgIJL4xO4cAgGgUu7WN2OatuEpO+5benW+fBgGw29q7HSBjWZj9+5PRvz+2qx/tafk01gpfD/kRWdk7yGrYji/ajM/RjpGWQ1o4grOpBjMWJWZ5iPiycVgmPkLYdoh6Ty4RdyZWNEQEDxGHC1tMXHaYWHoGNDdjRqM4JA5G4khELCdNho/cNBdNgTgEg/glnex0oaFl7+gmHIWA7B2aOB2Q4e0cBoPaAORlASTmOQw47UShptHoFoIOHWEYFE0EU1pa99GBiYN3u60NMz39SN6Ko0aDABCP7Xdxv7Q4DDAJReO0h00C/U8kXHAS+a1rMXdtxYhG8JpgxMJIJIzDjuIy3ODyQRQs0yDLEycqcWxPWmJYldi3cDmEmNNLLJROzOHACsaxDMFwObEdThxeL9UtLrJ9BobbA3FoagWXE8KRxCd5a0gI5/RPabPTAW6n4HElxvmRmNDYapCTaWAa4HIK67Yb9PMJnU8AdBUMQ3XUxwk0Iz31k2nCnjNXRKPdlx8j9FojwPB6wdz3zmBm+BiQbXDKQAeD88HrMRiaF8ZTuwvDjifLOdxOHA4TtxEn224jI81AnC7EsrCcFtm+xGlLhwNcFnjTTGyXG8MwiOTkE0nPxnalEXV5sR0uTJ+PcHYemV4jcZYpfxDidBO3IRYDtytRn6t/FqHMnJQ2ByPgcRnJ06SWwyBrz4d1VrpBmsvEMqG+Rdh7srU7hwl5J+diuJwY7u6XYJjZey8zMTzH7hkk/UYADMvCMWAA8Zrd3Zc5LczcXCAxznZaDkoHC1XbbcxwMKWs6XLi8XghGgE7jtvnguxsWutbyPSAJ8OHI9ROSztYLohk9iPTZRCOgm162H3SaVg7P8Njh7DdTkzLIis9sTOLwyKeM4B4/zyspnribS3YloFjUD8sVz+yghBoS+zQDhOy0xNDJkiEIC8r8W9nGV6D/V1z5zBhcIGB1+1ETh0GLhd2UyDxNWRZmFlZmHsuLzH7ZWN43If7Fhx1GoQ9HEUDwTCw/f7kQbPp8+EYfCKGc+8vu/18BmAw6AQnjS4XRCJA4oyPNzsN2m2w0jCzsrEGFWEB7pxMLJcDD2C0NGO6bJqsLOKeDPK8EIoKWxyFmA6L9hOHkdG4GSMeI9PbEQIHkaKTwUwcB8Ry8iEnnwiJ4U+WC9hzXVNrSBiQZWA5Ep/2kWjPIQDI9MKJA0zqm0leGpLsj2QIEusZbjeuH56K44QCYhs3I7advJbKzM7CGjK4196Lo0GDsIdhGFhFA5ETCpBQCMNh7fcTzpflxh5SQGDDDixTyPAaGEY6Eosi8ThmTr9kWVduP6xThoJh4BpRiv3NbsLbajFsG8PrxZlbQK4jC0creFwZeIeUUCBN1NWFiDjdxDP7J8ZTXThMKMozSXOBYQhOy2BwvkFDS2J5QT9wO6E1uK8QGBiGkbjWiL1h6BqClG1mZ2OeUY60tCR+WEtLwzgOflTTIHRhOBwYB3HmwzAMfD/8AUYsiqOlCUIhME3MQYMwvWmJy6HdbszsbIyszOSnp+F2k19yIgwchL/RBsPAMKA0zyASFZrahBPznLhdA3CdIGz3S49D+K47a1HuntOtloHTEhpbhZMLTCwHVNUJTZ1O+HQOQYfcrMTf/ibZZwg6v3YjM/MgevPYoUE4Ao4BeaSXCPHqaiSaOKNieNOwThyEmbH/C3fy+xmASW1AGJRnkJWeGHLlZe8tk+k1OHFA4krWzmP5nj6xDcPAuefdHJBtkJMJDnNvSCARhp5C0CE3yyDb1/Mw6ninQThCjvwBmHm5SDCE4TAxPJ6DXje/X+JMTscpzp50DcP+hi0p7TJTQ1KUC2kuyMlkvzf/fB9DAHr6tFcYpomZ7j2kEHTYXwg6JMKQOAA+mBD02EbDIDer528Cpd8Ix4xMr4GvCMz9/N6hDp9+IxxDNATfHg2CUmgQlAI0CEoBGgSlAA2CUoAGQSlAg6AUoEFQCtAgKAVoEJQCNAhKARoEpQANglKABkEpQIOgFKBBUArQICgFaBCUAjQISgEaBKUADYJSgAZBKUCDoBSgQVAK0CAoBWgQlAI0CEoBGgSlAA2CUoAGQSlAg6AUoEFQCtAgKAVoEJQCNAhKARoEpQANglKABkEpQIOgFKBBUArQICgFaBCUAjQISgEaBKUADYJSgAZBKUCDoBSgQVAK0CAoBWgQlAI0CEoBGgSlAA2CUoAGYZ+iG77p8W+AD76ME93wDcEVbwOwtcYGOOB0R107PviarTV28t+ude/89/9Lzu+87a5lu7ax8/KOv7uu03V+19fWtXxPOtbpuu6xTIOwD/sLwvoqm+iGb4is/QyArbsF4IDTHXW1frGRrbsl+W/XuuOffZ6cnxKELmW7BaHT8o6/u67TdX63IHQp3xMNglLHKQ2CUmgQlAI0CEoBGgSlAA2CUoAGQSlAg6AUoEFQCtAgKAVoEJQCNAhKARoEpQCwervCeDwOQE1NTW9X/Z0KNTTgqarq9jdAU32MXdEGoi3NtFRVUee3qaoyaTnAdEdduwNCnX8nBBqo8+9MLuuou6a1OTm/87Y719NTG+vce+vqKNt1na7zu762ruX31zdd1z1aOva1jn3vcBgicuDrbg/Bu+++y4033tibVSp1UJ5++mnOPffcw1q3178RBg0aBMDf//53Bg4c2NvVH7dqamqYPHkyzz33HAUFBUe7OceUnTt3cs011yT3vcPR60FwuVwADBw4kKKiot6u/rhXUFCg/XaYOva9w6EHy0qhQVAK0CAoBXwLQcjMzGTGjBlkZmb2dtXHNe23w9cbfdfrp0+VOhbp0EgpNAhKAb0UhGXLlnHRRRcxcuRIrrvuOnbs2LHPsq2trQwbNqzbfw0NDb3RlD4tGo3yu9/9jtGjRzN69GgefvhhbLvnJ8u1tLQwa9YszjjjDCorK1m0aNF33Nq+41D6bcmSJd32rWnTph14I3KE1q1bJ6WlpfL888/Lhg0bZMaMGTJhwgSJxWI9lv/0009lxIgR4vf7U/6zbftIm9LnPfDAA3LBBRfImjVrZOXKlTJ27Fh56qmneiw7c+ZMmThxonz11VfyxhtvSFlZmbz66qvfcYv7hkPpt7lz58qcOXNS9q1AIHDAbRxxEObMmSO33HJLcrqtrU3Kysrk3Xff7bH8Sy+9JJdddtmRbvaYEwqFZOTIkfLOO+8k57388ssyduzYbh8CVVVVMmzYMPnmm2+S8+bPny9XXnnld9bevuJQ+k1E5Oqrr5ZFixYd8naOeGj06aefMmrUqOS01+tl+PDhrFmzpsfymzZtYsiQIUe62WPOV199RTAYpKKiIjmvoqKC2tpaqrpcwblmzRqys7MZOnRoStl169YRjUa/szb3BYfSb3D4+9cRB2H37t0MGDAgZV5ubu4+L8PeuHEj9fX1XHXVVZxzzjlMmzaNzZs3H2kz+rzdu3fj8/lIT09PzsvLy0su61q2a5/m5eURi8Woq6v79hvbhxxKv9XX19PY2Mgbb7zBeeedx/nnn88jjzxCJBI54HYOeNFdOBze506dlZVFKBTqdrGTy+Xa58Y3bdpERkYGd911F263myeffJJrrrmG119//bj+MSkYDOJ2u1PmdfRb1746lLLHu0Ppi02bNgGQkZHBn//8Z7Zu3cr//d//0dzczH333bff7RwwCJ9//jmTJ0/ucdmMGTPweDzdvq4jkQgZGRk9rvPaa69hGAYejweAefPmce655/LWW29xxRVXHKg5xyyPx9PtjeuY7uiLwyl7vDuUvhg1ahQffPAB/fr1A+DUU08FYNasWdx11137vTr1gEGoqKjg66+/3ufy1157Db/fnzKvtrY2ZXzbWVpaWsq02+2mqKioWx3Hm4KCAlpaWggGg8k+qK2tBSA/P79b2Y5lHfx+P06nM/kmf18cSr8B3fpn6NChxGIxGhoa9nufxxEfI5SXl7Nq1arkdHt7O19++SXl5eXdygYCAc4880zee++95Ly2tja2bdvGySeffKRN6dNOPfVU0tLSUvrqk08+YcCAAd1uYCorK6O+vp4tW7Yk561atYqSkpIjuub+WHQo/fbCCy9w3nnnpfzG8OWXX+Lz+bodc3VzJKe2REQ+++wzGT58uCxZskQ2bNggM2fOlEsvvVTi8biIiASDQfH7/cnyN954o1x88cWyatUqWb9+vUybNk0uvvhiiUajR9qUPu/++++X888/X1atWiXvv/++jB07Vv7yl7+IiEhjY6M0Nzcny06bNk2uvPJKWbdunbz55ptSVlYmr7/++tFq+lF1sP22Y8cOKSsrk3vvvVe2bNkiK1askLFjx8qCBQsOuI0jDoKIyKuvvirjx4+XkSNHynXXXSfbt29PLvvnP/8pxcXFyemmpia588475ayzzpKysjK56aabZNeuXb3RjD4vFArJ3XffLeXl5TJmzBh5+OGHk+fCp0yZIrNnz06WbWxslJkzZ8qIESOksrJS/va3vx2tZh91h9Jvn3zyiUycOFFGjhwplZWV8sQTTxzUj7V69alS6EV3SgEaBKUADYJSgAZBKUCDoBSgQfjeOpyThcfzCcZjIgjLly9n7Nix3eZ3vROppKSE8847j9///vc0NzcfhZb2fYFAgF//+tcpv1ofSCQS4b777uP9999Pzhs2bBjPP//8t9HEo6LXH/nY29auXcvs2bP3ebHZ1KlTOf/88wEIhUJs3LiRBQsW8L///Y/nn38en8/3XTa3z1u/fj1vvPEGM2fOPOh1/H4/S5cuZdy4ccl5//jHP47oWaN9TZ8NQiwW49lnn+VPf/rTfq+4LCoqoqysLDk9ZswYxowZw89+9jOefPJJbr/99u+gtd8/nfv8eNBnh0arVq1i/vz53HbbbUyZMuWQ1h06dCgXXnghL7/88j7LzJ8/n0mTJnHvvfdSXl7ODTfcACRump87dy6jR4+mrKyM6dOns3PnzpT1Lr/8cl566SUqKys544wzuO2222hqakqWGT9+PI8++ig//elPGTlyJK+88gqQuJtv0qRJjBgxgsrKSubPn59ygdimTZu4/vrrOf3006moqGDGjBkpD0IQEZ5++mnGjx9PaWkpl19+OR9++GFy+YcffsiwYcNYvXo1V1xxBaWlpVx44YUsX748ufyaa64BYMKECcyfPx9IPIn7jjvu4Oyzz2b48OGMHz+eBQsWAFBVVcV5550HwA033MCcOXOA7kOjdevW8ctf/pKKigrGjBnD3LlzaWlpSS7/xS9+wcMPP8yDDz7ImDFjKC8vZ9asWbS2th7w/fxOfBvXhvSGuro6aWhoEBGRxx9/XM4+++xuZYqLi2Xp0qU9rv/yyy9LcXFxynVPnT3++ONy2mmnydSpU+X999+X999/X+LxuEyaNEkqKyvlX//6lyxbtkwuv/xyGT9+vLS2tibXKy8vl7Fjx8orr7wi//73v+Wss86SKVOmJOseN26cDB8+XBYtWiRvvfWW1NTUyFdffSWlpaUyffp0eeedd2Tx4sUycuRIeeCBB0REJB6PywUXXCDXX3+9vPfee7J8+XK56KKL5IorrkjW+8gjj0hJSYk8+eST8u6778ptt90mJSUl8sUXX4iIyAcffCDFxcUybtw4WbJkiaxcuVKuu+46KS0tlcbGRmlpaZFnn31WiouL5bXXXpPq6mqJx+NyySWXyBVXXCHLly+XlStXyl133SXFxcXy3//+V8LhsLz11ltSXFwsixYtkm3btnXr+88//1xKSkrkhhtukLfffltefPFFOeuss2TixInJhzhMmTJFTj/9dJk2bZq8++67snTpUikpKZE//vGPB79TfIv6bBA6O5wgvPPOO1JcXCxr1qzZZ53FxcWyZcuWbut8+umnyXmBQEDKy8uTN4R3rPfBBx8ky7z99ttSXFwsa9euFZFEECZOnJiyvVtuuaXb0z1efPFFGT58uNTV1Ynf75fi4mL5z3/+k1z+6aefyrx58yQWi0ljY6OUlJR0e3rD1VdfLTfddJOI7A1C5z7ZvHmzFBcXy5tvvplSZuPGjSIisnPnTpkyZYps2rQpuY5t21JRUSGPPfaYiCSu6iwuLk55IEPn7dx8881y4YUXpry2jz/+WIqLi2XZsmUikghCZWVlylXGt912m1x66aXSF/TZodF3wbKslAO+jz76iOzsbEpKSojFYsRiMbxeL2VlZSlDkNzcXEaPHp2cPvfcc3E6naxevTo5r+sN5B9//DFjx45FRJJ1V1ZWEo1GWb16NTk5OQwePJi5c+dy9913s2LFCk499VRuvfVWHA4Ha9euJRKJUFlZmVw/FotxzjnnpLQNYOTIkcm/O25GCQaDPfZBYWEhS5Ys4aSTTmLz5s2sWLGCJ554glgsdtAPCli1ahUXXHABDocjOa+iooK8vLyU+wiGDx+OZe09LM3Pz6e9vf2gtvFt67MHy0eq4y6mjhu9e5KdnZ3y5jU1NdHU1MTw4cO7lS0tLU3+3bVOwzDIzs4mEAgk5+Xk5KSUaWpqYvHixSxevLhb3X6/H9M0WbRoEfPnz+fNN9/kpZdewufzceONNzJt2rTkMchPfvKTHl9L5x298z2+ppn4rNvXA7EgcQbo0UcfpbGxkRNOOIEzzjgDy7IO+neD5ubmbq8XEn3Q+Rig60kP0zT7zG8Tx20QPv74Y/Lz8yksLDzodTIzMxk4cCCPPfZYt2WdbzHtvMNDYidrbGykf//++6w7IyODSy+9tMcduaONhYWF/OEPf+D+++9n9erVybNmo0aNSj7YYOHChWRlZXWr43DvXPvoo4+49957mTVrFj//+c+TdZ999tkHXUdmZib19fXd5tfX1/fY1r7ouBwabdu2jTfffPOQHwZQXl6O3+8nJyeH0tJSSktLKSkpYdGiRaxcuTJZrrq6mg0bNiSn33nnHWKxGGeeeeZ+6966dWuy3tLSUizLYt68edTX17N582bOOecc1q1bh2VZjBo1invuuQdInNUZMWIElmURCARS6li5ciXPP/98yjfb/nQtt2bNGtxuNzfccENyp12/fj319fXJb5ED1X366afz1ltvpfxfLT/55BNqa2uPmdOsx/w3QlVVVfJhYqFQiPXr17Nw4UIGDx7M1KlTD6mucePGccoppzB16lRuvvlm+vfvz4svvsiyZcuYNGlSStmZM2cya9Ys2traeOihh/jxj3+cfGpCT6ZPn87kyZP5zW9+w4QJEwgEAjz66KOkpaUxZMgQHA4HmZmZzJkzh5kzZ+Lz+Vi6dCkZGRmMHj2a/v37c9VVV/Hb3/6Wuro6hg0bxkcffcSCBQu49dZbD/o1djxdZMWKFbjdbkpLSwmFQjz44IOMGzeOrVu38sQTT2AYRnK41bHOe++9R1FRUbf7y6dPn87VV1/NTTfdxOTJk6mtrWXevHmUlpbyox/96KDbdjQd80F45plneOaZZwBIT0+nsLCQyy67jOnTp+P1eg+pLqfTycKFC3nooYe4//77CYfDFBcXs2DBgpRP+5ycHK699lruvfdebNtmwoQJzJ49e791l5WVsXDhQubNm8evfvUr0tPTOeecc7jjjjtwOp0APPnkkzzwwAPMnTuXUChEaWkpf/3rX5NDrjvvvJN+/fqxePFiamtrKSwsZPbs2Vx33XUH/RpPOeUULrnkEh5//HFqamq45557uOOOO1iyZAlLly6lsLCQa6+9lo0bN7J27VoAfD4f119/Pc899xzbt2/nqaeeSqlzxIgRLFq0iEceeYQZM2aQkZHB+eefz+23355ycNyX6a2ah2j+/Pm88MILKUMldew7Lo8RlDpUGgSl0KGRUoB+IygFaBCUAjQISgEaBKUADYJSgAZBKQD+P39F7cQz6JQ2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 201.6x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import moment\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier\n",
    "from os import listdir\n",
    "import random\n",
    "from os.path import isfile, join\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "np.random.seed(200)\n",
    "sns.set(font_scale=1.3)\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "number_of_experiment = 50\n",
    "\n",
    "fig=plt.figure(figsize=(1.4*2, 1.5*2))\n",
    "mypath = \"./data\"\n",
    "\n",
    "full_data = []\n",
    "for size in [8]:\n",
    "    full_X = []\n",
    "    label = []\n",
    "    \n",
    "    for depth in [5]:\n",
    "        config = \"1D-scramble-C-size-{}-depth-{}-\".format(size, depth)\n",
    "\n",
    "        list_pred = []\n",
    "        for b in range(0, 20, 5):\n",
    "            for i in range(0, 5):\n",
    "                data = np.load(join(mypath, config+'type-0-batch-{}-number-{}.npy'.format(b, i)))\n",
    "                data = np.random.permutation(data)[:number_of_experiment]\n",
    "                feature_vec = np.concatenate((np.mean(data, axis=0), [np.std(np.mean(data, axis=0))]))\n",
    "                \n",
    "                full_X.append(feature_vec)\n",
    "                label.append([\"General\", depth])\n",
    "\n",
    "    for depth in [5]:\n",
    "        config = \"1D-scramble-C-size-{}-depth-{}-\".format(size, depth)\n",
    "\n",
    "        for b in range(0, 20, 5):\n",
    "            for i in range(0, 5):\n",
    "                data = np.load(join(mypath, config+'type-1-batch-{}-number-{}.npy'.format(b, i)))\n",
    "                data = np.random.permutation(data)[:number_of_experiment]\n",
    "                feature_vec = np.concatenate((np.mean(data, axis=0), [np.std(np.mean(data, axis=0))]))\n",
    "\n",
    "                full_X.append(feature_vec)\n",
    "                label.append([\"T-symmetry\", depth])\n",
    "\n",
    "    full_X = np.array(full_X)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    full_X = min_max_scaler.fit_transform(full_X)* 0.8\n",
    "    transformer = KernelPCA(n_components=2, kernel='rbf')\n",
    "    X_transformed = transformer.fit_transform(full_X)\n",
    "\n",
    "    full_data.extend([x + y for x, y in zip(X_transformed.tolist(), label)])\n",
    "    \n",
    "df = pd.DataFrame(full_data, columns=['x', 'y', 'Evolution', 'Depth'])\n",
    "\n",
    "\n",
    "sns.rugplot(data=df[df[\"Evolution\"]==\"General\"], x=\"x\", hue=\"Evolution\", alpha=.5, height=0.1, palette=[\"#80A3FA\"])\n",
    "sns.rugplot(data=df[df[\"Evolution\"]==\"T-symmetry\"], x=\"x\", hue=\"Evolution\", alpha=.5, height=0.1, palette=[\"#ED686D\"])\n",
    "g = sns.stripplot(data=df[df[\"Evolution\"]==\"General\"], x=\"x\", hue=\"Evolution\", marker=\"D\", jitter=0.03, size=8, alpha=0.35, palette=[\"#80A3FA\"])\n",
    "g.set(yticks=[])\n",
    "g = sns.stripplot(data=df[df[\"Evolution\"]==\"T-symmetry\"], x=\"x\", hue=\"Evolution\", marker=\"o\", jitter=0.03, size=8, alpha=0.35, palette=[\"#ED686D\"])\n",
    "g.set(yticks=[])\n",
    "plt.xlim(-0.5, 0.5)\n",
    "plt.xlabel(\"1D representation\")\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "plt.legend([], [], frameon=[])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf42f8a",
   "metadata": {
    "id": "26086621407b"
   },
   "source": [
    "# Learning dynamics with quantum-enhanced experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f62974",
   "metadata": {
    "id": "4fca7c48810a"
   },
   "source": [
    "Using kernel principal component analysis to analyze data from quantum-enhanced experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86d18502",
   "metadata": {
    "id": "274b45e35277"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fcbde4d4250>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 201.6x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import moment\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier\n",
    "from os import listdir\n",
    "import random\n",
    "from os.path import isfile, join\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "np.random.seed(200)\n",
    "sns.set(font_scale=1.3)\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "number_of_experiment = 50\n",
    "\n",
    "fig=plt.figure(figsize=(1.4*2, 1.5*2))\n",
    "mypath = \"data\"\n",
    "\n",
    "full_data = []\n",
    "for size in [8]:\n",
    "    full_X = []\n",
    "    label = []\n",
    "    \n",
    "    for depth in [5]:\n",
    "        config = \"1D-scramble-Q-size-{}-depth-{}-\".format(size, depth)\n",
    "\n",
    "        list_pred = []\n",
    "        for b in range(0, 20, 5):\n",
    "            for i in range(0, 5):\n",
    "                data = np.load(join(mypath, config+'type-0-batch-{}-number-{}.npy'.format(b, i)))\n",
    "                data = np.random.permutation(data)[:number_of_experiment]\n",
    "                feature_vec = np.concatenate((np.mean(data, axis=0), [np.std(np.mean(data, axis=0))]))\n",
    "                \n",
    "                full_X.append(feature_vec)\n",
    "                label.append([\"General\", depth])\n",
    "\n",
    "    for depth in [5]:\n",
    "        config = \"1D-scramble-Q-size-{}-depth-{}-\".format(size, depth)\n",
    "\n",
    "        for b in range(0, 20, 5):\n",
    "            for i in range(0, 5):\n",
    "                data = np.load(join(mypath, config+'type-1-batch-{}-number-{}.npy'.format(b, i)))\n",
    "                data = np.random.permutation(data)[:number_of_experiment]\n",
    "                feature_vec = np.concatenate((np.mean(data, axis=0), [np.std(np.mean(data, axis=0))]))\n",
    "\n",
    "                full_X.append(feature_vec)\n",
    "                label.append([\"T-symmetry\", depth])\n",
    "\n",
    "    full_X = np.array(full_X)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    full_X = min_max_scaler.fit_transform(full_X)* 0.8\n",
    "    transformer = KernelPCA(n_components=2, kernel='rbf')\n",
    "    X_transformed = transformer.fit_transform(full_X)\n",
    "\n",
    "    full_data.extend([x + y for x, y in zip(X_transformed.tolist(), label)])\n",
    "    \n",
    "df = pd.DataFrame(full_data, columns=['x', 'y', 'Evolution', 'Depth'])\n",
    "\n",
    "\n",
    "sns.rugplot(data=df[df[\"Evolution\"]==\"General\"], x=\"x\", hue=\"Evolution\", alpha=.5, height=0.1, palette=[\"#80A3FA\"])\n",
    "sns.rugplot(data=df[df[\"Evolution\"]==\"T-symmetry\"], x=\"x\", hue=\"Evolution\", alpha=.5, height=0.1, palette=[\"#ED686D\"])\n",
    "g = sns.stripplot(data=df[df[\"Evolution\"]==\"General\"], x=\"x\", hue=\"Evolution\", marker=\"D\", jitter=0.03, size=8, alpha=0.35, palette=[\"#80A3FA\"])\n",
    "g.set(yticks=[])\n",
    "g = sns.stripplot(data=df[df[\"Evolution\"]==\"T-symmetry\"], x=\"x\", hue=\"Evolution\", marker=\"o\", jitter=0.03, size=8, alpha=0.35, palette=[\"#ED686D\"])\n",
    "g.set(yticks=[])\n",
    "plt.xlim(-0.5, 0.5)\n",
    "plt.xlabel(\"1D representation\")\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "plt.legend([], [], frameon=[])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Data-Analysis.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
